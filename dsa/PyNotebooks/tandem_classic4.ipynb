{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Science Avancées"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:green; font-weight: bold;'> Importation des modules, Variables globales, etc </span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import _criterion\n",
    "from globals import FILES_PATH\n",
    "\n",
    "# import matplotlib.cm as cm\n",
    "\n",
    "document_name = \"classic4\"\n",
    "document2vec_name = \"classic4_doc2vec\"\n",
    "\n",
    "datasets_path = Path.cwd().parent.parent / \"core\" / \"datasets\" / \"data\"\n",
    "print(datasets_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMAGES_PATH = Path.cwd().parent.parent / \"images\" / \"unsupervised_learning\" / f\"{document_name}\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:green; font-weight: bold;'>Chargement des données bbc</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer=f'{datasets_path}/{document_name}.csv',\n",
    "    usecols=['text', 'label']\n",
    ")\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_classic4 = df.copy()\n",
    "df_classic4.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = df_classic4['label'].unique()\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_unique_labels = list(df_classic4['label'].unique())\n",
    "list_unique_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:green; font-weight: bold;'>Analyse exploratoire des données</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Y-a-t'il des reviews vides?\n",
    "df_classic4['text'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def target2counts(df_doc: pd.DataFrame) -> {str: int}:\n",
    "    \"\"\"\n",
    "    Count number of document per label\n",
    "    :param df_doc:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    targets = list(df_doc.label)\n",
    "    target_counter = Counter(targets)  # -> dico\n",
    "    return target_counter\n",
    "\n",
    "target2counts(df_classic4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combien de mots dans chaque review ?\n",
    "word_counts = df_classic4['text'].apply(lambda x: len(x.split())) # pd.series\n",
    "word_counts.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = plt.boxplot(word_counts.values)\n",
    "plt.grid(True)\n",
    "save_fig(f\"{document_name}_words_box_plot\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# NB :\n",
    "# La plupart des reviews ont entre 250 et 475 mots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = plt.boxplot(word_counts.values)\n",
    "plt.ylim(100, 900)\n",
    "plt.grid(True)\n",
    "save_fig(f\"{document_name}_words_box_plot_zoomed\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:green; font-weight: bold;'>Nettoyage des données textuelles</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On enchaîne dans la fonction *data_preprocessing* les méthodes de nettoyage classiques vues précédemment.\n",
    "\n",
    "* suppression des tag HTML\n",
    "* conservation des mots uniquement\n",
    "* passage en minuscule\n",
    "* *(tokenization)*\n",
    "* lemmatisation\n",
    "* *(réassemblage des reviews)*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from core.preprocessing import Corpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cp = Corpus()\n",
    "df_classic4 = cp.process_documents(df_classic4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_classic4.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:green; font-weight: bold;'>Représentation vectorielle de données textuelles</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dans cette partie, nous souhaitons représenter notre corpus de documents en matrice document-terme $\\mathbf{X}$ de taille $N\\times V$, $N$ étant le nombre de documents et $V$ le nombre total de mots présents dans le vocabulaire. Exemple avec $N=2$ et $V=9$ :\n",
    "<img src=\"https://drive.google.com/uc?id=1jdz0lyVCH-7ZfxC5dpj_34f34rBWKs52\" width=700>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1_ère approche: Bag-Of-Words (BOW)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vectorizer = CountVectorizer(min_df=10)\n",
    "X_docs_bow = bow_vectorizer.fit_transform(df_classic4['text'])\n",
    "print('X_docs_bow shape: ', X_docs_bow.shape)\n",
    "\n",
    "# NB:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import count_nonzero\n",
    "\n",
    "nb_nonZero = count_nonzero(X_docs_bow.todense())\n",
    "my_size = float(X_docs_bow.todense().size)\n",
    "print(\"Nombre d'éléments non nuls : \", nb_nonZero)\n",
    "print(\"Nombre d'éléments : \", my_size)\n",
    "print(\"Sparsité : \", 1-(nb_nonZero/my_size))\n",
    "\n",
    "# NB:\n",
    "# On a une matrice très sparse!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2_ème approche: Pondération matrice *documents x termes* par TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5, # ignoring terms that appear in more than 50% of the documents (as set by max_df=0.5)\n",
    "    min_df=5,   # ignoring terms that are not present in at least 5 documents (set by min_df=5)\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "t0 = time()\n",
    "X_docs_tfidf = tfidf_vectorizer.fit_transform(df_classic4['text'])\n",
    "print('X_docs_bow shape: ', X_docs_tfidf.shape)\n",
    "print(f\"vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"n_samples: {X_docs_tfidf.shape[0]}, n_features: {X_docs_tfidf.shape[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import count_nonzero\n",
    "\n",
    "nb_nonZero = count_nonzero(X_docs_tfidf.todense())\n",
    "my_size = float(X_docs_tfidf.todense().size)\n",
    "print(\"Nombre d'éléments non nuls : \", nb_nonZero)\n",
    "print(\"Nombre d'éléments : \", my_size)\n",
    "print(\"Sparsité : \", 1-(nb_nonZero/my_size))\n",
    "\n",
    "# NB:\n",
    "# On a une matrice très sparse!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3_ème approche: Word embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <span style='color:#3390FF; font-weight: bold;'>Word2Vec representation of words</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exécuter les sections suivantes si vous n'avez pas encore chargé et sauvegardé les vectors dans le model dédié"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from globals import embeddings_path\n",
    "\n",
    "# 2nd alternative\n",
    "word2vec_file = embeddings_path\n",
    "# we could load keyed vector by specifying that there is no header (dim shape) on top of file.\n",
    "words_vectors_from_text = KeyedVectors.load_word2vec_format(word2vec_file, binary=False, no_header=True)\n",
    "\n",
    "# 1st way\n",
    "# load keyed vector build by own\n",
    "# word2vec_file = f'{datasets_path}/../glove_model2.txt'\n",
    "# word2vec_trained_model = KeyedVectors.load_word2vec_format(word2vec_file, binary=False)\n",
    "\n",
    "\n",
    "# 3rd alt: only if we store data on gensim site_package folder\n",
    "# words_vectors_from_text = KeyedVectors.load_word2vec_format(datapath('glove.840B.300d.txt'), binary=False, no_header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sauvegarder le model pour une reproductibilité\n",
    "# words_vectors_from_text.save('word2vec.wordvectors')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# charger les vecteurs depuis la projection mémoire, partagée par les processus\n",
    "# words_vectors_from_mapping = KeyedVectors.load('word2vec.wordvectors', mmap='r')\n",
    "# print(words_vectors_from_mapping)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finding similar words\n",
    "# The most_similar() function finds the cosine similarity of the given word with\n",
    "# other words using the word2Vec representations of each word\n",
    "# result = words_vectors_from_mapping.most_similar('king', topn=5)\n",
    "# result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculons: (king - man) + woman = ?\n",
    "#result = words_vectors_from_mapping.most_similar(\n",
    "#    positive=['woman', 'king'],\n",
    "#    negative=['man'],\n",
    "#    topn=1\n",
    "#)\n",
    "#result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# voir la taille d'un vecteur de mot\n",
    "# words_vectors_from_mapping['hello'].shape\n",
    "# model['hello']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#'hello' in words_vectors_from_mapping.key_to_index.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#computer_vector = words_vectors_from_mapping['computer']  # Get numpy vector of a word\n",
    "#computer_vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons maintenant récupérer la représentation des mots du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0,\"..\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from core.word_embedding import Word2VecVectorizer\n",
    "\n",
    "# Set a word2vec vectorizer\n",
    "vectorizer = Word2VecVectorizer(model=words_vectors_from_text)\n",
    "# Get the sentence embeddings for the train dataset\n",
    "X_w2v = vectorizer.fit_transform(df_classic4['text'])\n",
    "print('X_w2v shape: ', X_w2v.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_X_w2v = pd.DataFrame(data=X_w2v, columns=[f\"V{i}\" for i in range(X_w2v.shape[1])])\n",
    "df_X_w2v = pd.concat([df_X_w2v, df_classic4['label']])\n",
    "df_X_w2v.head()\n",
    "#df_X_w2v.to_csv(path_or_buf=FILES_PATH[\"classic4_doc2vec\"], sep=\",\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <span style='color:#3390FF; font-weight: bold;'>GloVe representation of words</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exécuter les sections suivantes si vous n'avez pas encore chargé et sauvegardé les vectors dans le model dédié"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### load glove vector into gensim object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from globals import embeddings_path\n",
    "\n",
    "glove_file = embeddings_path\n",
    "\n",
    "# we could load keyed vector by specifying that\n",
    "# there is no header (dim shape) on top of file.\n",
    "\n",
    "glove_words_vectors_from_text = KeyedVectors.load_word2vec_format(\n",
    "    fname=glove_file,\n",
    "    binary=False,\n",
    "    no_header=True\n",
    ")\n",
    "\n",
    "# sauvegarder les vecteurs de l'objet gensim dans un fichier\n",
    "# ---\n",
    "# glove_words_vectors_from_text.save('glove.wordvectors')\n",
    "\n",
    "# load\n",
    "# ---\n",
    "#glove_words_vectors_from_mapping = KeyedVectors.load('glove.wordvectors', mmap='r')\n",
    "# print(glove_words_vectors_from_mapping)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### load gensim object from file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# updated/new way to do that\n",
    "\n",
    "# glove_file = f'{datasets_path}/../glove.840B.300d.txt'\n",
    "# glove_trained_model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### save glove object into output file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deprecated way\n",
    "\n",
    "#(_,_) = glove2word2vec(\n",
    "#    glove_input_file=word2vec_file,\n",
    "#    word2vec_output_file=tmp_file\n",
    "#)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons maintenant récupérer la représentation des mots du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set a word vectorizer\n",
    "vectorizer = Word2VecVectorizer(model=glove_words_vectors_from_text)\n",
    "# Get the sentence embeddings for the train dataset\n",
    "X_glove = vectorizer.fit_transform(df_classic4['text'])\n",
    "print('X_glove shape: ', X_glove.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span style='color:green; font-weight: bold;'>Visualisation through Dimensionality Reduction</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from core.plot import points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topics = df_classic4['label'].unique()\n",
    "color_mapping = {topic: i for i, topic in enumerate(topics)}\n",
    "topic_colors = [color_mapping[topic] for topic in df_classic4['label']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bac-Of-Words X-matrix\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Principal Component Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # ne supporte pas la sparcité"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "l' **ACP** ne supporte pas les matrices très sparces"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "# >> pca = PCA(n_components=2)\n",
    "# >> result = pca.fit_transform(X_docs_bow)\n",
    "\n",
    "# Scatter plot de la projection\n",
    "# pyplot.scatter(result[:, 0], result[:, 1])\n",
    "# dico_terms_idx = result.vocabulary_\n",
    "# for i, word in enumerate(words):\n",
    "# \tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "# pyplot.show()\n",
    "\n",
    "# NB:\n",
    "# Il est difficile de tirer beaucoup de sens de ce graphique avec un\n",
    "# corpus aussi minuscule..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons trouver un autre alternative qui est la technique de dimensionnalité **LSA** connu sous le nom de **TruncatedSVD**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSA (aka TruncatedSVD)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# la svd fait une décomposition sans normalisation.\n",
    "# nous allons effectuer une normalisation pour optimiser les résultats\n",
    "n_components = 5\n",
    "lsa = make_pipeline(\n",
    "    TruncatedSVD(\n",
    "        n_components=n_components,\n",
    "        n_iter=2500,\n",
    "        random_state=123\n",
    "    )\n",
    "    ,\n",
    "    Normalizer(copy=False)\n",
    ")\n",
    "\n",
    "t0 = time()\n",
    "X_docs_bow_red_lsa = lsa.fit_transform(X_docs_bow)\n",
    "explained_variance = lsa[0].explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"LSA done in {time() - t0:.3f} s\")\n",
    "print(f\"Explained variance of the SVD step: {explained_variance * 100:.1f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "nth_dims = (0, 1)\n",
    "points.plot2d(\n",
    "    ax=ax,\n",
    "    x=X_docs_bow_red_lsa[:, nth_dims[0]],\n",
    "    y=X_docs_bow_red_lsa[:, nth_dims[1]],\n",
    "    nth_dim=nth_dims,\n",
    "    target_names=topics,\n",
    "    target_idx_colors=topic_colors,\n",
    "    s=6,\n",
    "    t='2D projection (random nb component) of the X (BOW) matrix using Incremental-PCA'\n",
    ")\n",
    "save_fig(f\"{document_name}_bow_IPCA_2Dplot\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons tenter d'explorer un peu les résultats, en cherchant nombre d'axes factoriels, nous permettant de préserver un certains ```%centage``` de variance de nos données, dans un but purement représentative."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# la dimension fitté par le modèle\n",
    "lsa2 = TruncatedSVD()\n",
    "lsa2.fit(X_docs_bow)\n",
    "cumsum2 = np.cumsum(lsa2.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum2 >= 0.95) + 1  # d equals 1\n",
    "d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "la matrice étant très sparce, il ne faut qu'1 seul dimension, on va essayer de confirmer ce résulat via le graphique en ```coude```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(cumsum2, linewidth=3)\n",
    "plt.axis([0, 5, 0, 1])\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.plot([d, d], [0, 0.95], \"k:\")\n",
    "plt.plot([0, d], [0.95, 0.95], \"k:\")\n",
    "plt.plot(d, 0.95, \"ko\")\n",
    "plt.annotate(\"Elbow\", xy=(10, 0.1), xytext=(70, 0.7),\n",
    "             arrowprops=dict(arrowstyle=\"->\"))\n",
    "plt.grid(True)\n",
    "#save_fig(\"explained_variance_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\rightarrow$ vers une approche ICPA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Etant donné que l'on a une matrice très sparse, nous allons explorer une autre approche de PCA qui nous permettra de faire\n",
    " en même temps du PCA, de l'imputation. En d'autre terme, nous ferons une imputation à l'aide du PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Incremental PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "# choix arbitraire\n",
    "n_components = 2\n",
    "ipca = IncrementalPCA(\n",
    "    n_components=n_components,\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "X_docs_bow_red_ipca = ipca.fit_transform(X_docs_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "nth_dims = (0, 1)\n",
    "points.plot2d(\n",
    "    ax=ax,\n",
    "    x=X_docs_bow_red_ipca[:, nth_dims[0]],\n",
    "    y=X_docs_bow_red_ipca[:, nth_dims[1]],\n",
    "    nth_dim=nth_dims,\n",
    "    target_names=topics,\n",
    "    target_idx_colors=topic_colors,\n",
    "    s=5,\n",
    "    t='2D projection (random nb components) of the X (BOW) matrix using Inremental-PCA'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nombre de composant principal fitté par le model\n",
    "inc_pca = IncrementalPCA()\n",
    "inc_pca.fit(X_docs_bow)\n",
    "inc_pca.n_components_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checker combien d'axe factoriel faut-il pour préserver 95% d'inertie de nos jeux de données\n",
    "inc_pca_ck = IncrementalPCA()\n",
    "inc_pca_ck.fit(X_docs_bow)\n",
    "inc_pca_ck_cumsum = np.cumsum(inc_pca_ck.explained_variance_ratio_)\n",
    "inc_pca_ck_d = np.argmax(inc_pca_ck_cumsum >= 0.95) + 1\n",
    "inc_pca_ck_d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Essayons de confirmer notre intuition via la méthode ou le graphique du **coude** ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(inc_pca_ck_cumsum, linewidth=3)\n",
    "plt.axis([0, 2300, 0, 1])\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.plot([inc_pca_ck_d, inc_pca_ck_d], [0, 0.95], \"k:\")\n",
    "plt.plot([0, inc_pca_ck_d], [0.95, 0.95], \"k:\")\n",
    "plt.plot(inc_pca_ck_d, 0.95, \"ko\")\n",
    "plt.annotate(\"Elbow\", xy=(550, 0.85), xytext=(70, 0.7),\n",
    "             arrowprops=dict(arrowstyle=\"->\"))\n",
    "plt.grid(True)\n",
    "save_fig(\"BOW_IPCA_explained_variance_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# refaisons la projection\n",
    "inc_pca_ck2 = IncrementalPCA(\n",
    "    n_components=inc_pca_ck_d,\n",
    "    batch_size=1660\n",
    ")\n",
    "X_docs_bow_red_inc_pca_ck = inc_pca_ck2.fit_transform(X_docs_bow)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "nth_dims = (1, 3)\n",
    "points.plot2d(\n",
    "    ax=ax,\n",
    "    x=X_docs_bow_red_inc_pca_ck[:, nth_dims[0]],\n",
    "    y=X_docs_bow_red_inc_pca_ck[:, nth_dims[1]],\n",
    "    nth_dim=nth_dims,\n",
    "    target_names=topics,\n",
    "    target_idx_colors=topic_colors,\n",
    "    t='2D projection (nb components preserving 95% of inertia) of the X (BOW) matrix using Incremental-PCA'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Document embedding using UMAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot\n",
    "# umap.plot requires pandas matplotlib datashader bokeh holoviews scikit-image and colorcet to be installed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "X_docs_bow_umap_embedding = umap.UMAP(\n",
    "    n_components=2,\n",
    "    metric='hellinger'\n",
    ").fit(X_docs_bow)\n",
    "X_docs_bow_umap_embedding.embedding_.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For interactive plotting use\n",
    "# f = umap.plot.interactive(embedding, labels=dataset.target, hover_data=hover_df, point_size=1)\n",
    "# show(f)\n",
    "f = umap.plot.points(X_docs_bow_umap_embedding, labels=df_classic4['label'])\n",
    "\n",
    "#save_fig(\"bbc_BOW_UMAP_plot\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF-IDF X-matrix\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### La matrice reste sparce, et on ne peut pas appliquer le PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LSA (aka TruncatedSVD)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# la svd fait une décomposition sans normalisation.\n",
    "# nous allons effectuer une normalisation pour optimiser les résultats\n",
    "\n",
    "n_components=1065  # after fitting\n",
    "lsa = make_pipeline(TruncatedSVD(n_components=n_components), Normalizer(copy=False))\n",
    "t0 = time()\n",
    "X_docs_tfidf_red_lsa = lsa.fit_transform(X_docs_tfidf)\n",
    "explained_variance = lsa[0].explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"LSA done in {time() - t0:.3f} s\")\n",
    "print(f\"Explained variance of the SVD step: {explained_variance * 100:.1f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "nth_dims = (1, 2)\n",
    "points.plot2d(\n",
    "    ax=ax,\n",
    "    x=X_docs_tfidf_red_lsa[:, nth_dims[0]],\n",
    "    y=X_docs_tfidf_red_lsa[:, nth_dims[1]],\n",
    "    nth_dim=nth_dims,\n",
    "    target_names=topics,\n",
    "    s=2,\n",
    "    target_idx_colors=topic_colors,\n",
    "    t='2D projection (random nb components) of the X (TF-IDF) matrix using LSA'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons tenter d'explorer un peu les résultats, en cherchant nombre d'axes factoriels, nous permettant de préserver le plus de variance de nos données, dans un but purement représentative."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# la dimension fitté par le modèle\n",
    "lsa2_tfidf = TruncatedSVD()\n",
    "lsa2_tfidf.fit(X_docs_tfidf)\n",
    "cumsum2_tfidf = np.cumsum(lsa2_tfidf.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum2_tfidf >= 0.95) + 1  # d equals XXX\n",
    "d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "la matrice étant très sparce, il ne faut qu'1 seul dimension, on va essayer de confirmer ce résulat via le graphique en ```coude```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(cumsum2_tfidf, linewidth=3)\n",
    "plt.axis([0, 5, 0, 1])\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.plot([d, d], [0, 0.95], \"k:\")\n",
    "plt.plot([0, d], [0.95, 0.95], \"k:\")\n",
    "plt.plot(d, 0.95, \"ko\")\n",
    "plt.annotate(\"Elbow\", xy=(10, 0.1), xytext=(70, 0.7),\n",
    "             arrowprops=dict(arrowstyle=\"->\"))\n",
    "plt.grid(True)\n",
    "save_fig(f\"{document_name}_TFIDF_LSA_explained_variance_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\rightarrow$ vers une approche ICPAholoviews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Etant donné que l'on a une matrice très sparse, nous allons explorer une autre approche de PCA qui nous\n",
    "permettra de faire en même temps du PCA, de l'imputation. En d'autre terme, nous ferons une imputation à l'aide du PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Incremental PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "\n",
    "# choix arbitraire\n",
    "n_components = 2\n",
    "ipca = IncrementalPCA(n_components=n_components, batch_size=100)\n",
    "X_docs_tfidf_red_ipca = ipca.fit_transform(X_docs_tfidf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "nth_dims = (0, 1)\n",
    "points.plot2d(\n",
    "    ax=ax,\n",
    "    x=X_docs_tfidf_red_ipca[:, nth_dims[0]],\n",
    "    y=X_docs_tfidf_red_ipca[:, nth_dims[1]],\n",
    "    nth_dim=nth_dims,\n",
    "    target_names=topics,\n",
    "    s=1,\n",
    "    target_idx_colors=topic_colors,\n",
    "    t='2D projection (random nb components) of the X (TF-IDF) matrix using Incremental-PCA'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nombre de composant principal fitté par le model\n",
    "inc_pca_tfidf = IncrementalPCA()\n",
    "inc_pca_tfidf.fit(X_docs_tfidf)\n",
    "inc_pca_tfidf.n_components_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checker combien d'axe factoriel faut-il pour préserver 95% d'inertie de nos jeux de données\n",
    "inc_pca_tfidf_ck = IncrementalPCA()\n",
    "inc_pca_tfidf_ck.fit(X_docs_tfidf)\n",
    "inc_pca_tfidf_ck_cumsum = np.cumsum(inc_pca_ck.explained_variance_ratio_)\n",
    "inc_pca_tfidf_ck_d = np.argmax(inc_pca_ck_cumsum >= 0.95) + 1\n",
    "inc_pca_tfidf_ck_d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confirmons notre intuition à partir d'un graphique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(inc_pca_tfidf_ck_cumsum, linewidth=3)\n",
    "plt.axis([0, 2300, 0, 1])\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.plot([inc_pca_tfidf_ck_d, inc_pca_tfidf_ck_d], [0, 0.95], \"k:\")\n",
    "plt.plot([0, inc_pca_tfidf_ck_d], [0.95, 0.95], \"k:\")\n",
    "plt.plot(inc_pca_tfidf_ck_d, 0.95, \"ko\")\n",
    "plt.annotate(\"Elbow\", xy=(550, 0.85), xytext=(70, 0.7),\n",
    "             arrowprops=dict(arrowstyle=\"->\"))\n",
    "plt.grid(True)\n",
    "#save_fig(\"explained_variance_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_docs_tfidf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# refaisons la projection\n",
    "inc_pca_tfidf_new = IncrementalPCA(\n",
    "    n_components=inc_pca_ck_d,\n",
    "    batch_size=1800\n",
    ")\n",
    "X_docs_tfidf_red_inc_pca_new = inc_pca_tfidf_new.fit_transform(X_docs_tfidf)\n",
    "print('X_docs_tfidf_red_inc_pca_new: ', X_docs_tfidf_red_inc_pca_new.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "nth_dims = (0, 1)\n",
    "points.plot2d(\n",
    "    ax=ax,\n",
    "    x=X_docs_tfidf_red_inc_pca_new[:, nth_dims[0]],\n",
    "    y=X_docs_tfidf_red_inc_pca_new[:, nth_dims[1]],\n",
    "    nth_dim=nth_dims,\n",
    "    target_names=topics,\n",
    "    s=1,\n",
    "    target_idx_colors=topic_colors,\n",
    "    t='2D projection (nb components preserving 95% Inertia) of the X (TF-IDF) matrix using Incremental-PCA'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Document embedding using UMAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "X_docs_tfidf_umap_embedding = umap.UMAP(metric='hellinger').fit(X_docs_tfidf)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For interactive plotting use\n",
    "# fig = umap.plot.interactive(tfidf_embedding, labels=dataset.target, hover_data=hover_df, point_size=1)\n",
    "# show(fig)\n",
    "_ = umap.plot.points(X_docs_tfidf_umap_embedding, labels=df_classic4['label'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:#3390FF; font-weight: bold;'>Word2Vec representation of words</span>\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Principal Component Analysis (PCA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# choix arbitraire\n",
    "n_components = 2\n",
    "pca = PCA(n_components=n_components)\n",
    "X_w2v_pca = pca.fit_transform(X_w2v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "nth_dims = (0, 1)\n",
    "points.plot2d(\n",
    "    ax=ax,\n",
    "    x=X_w2v_pca[:, nth_dims[0]],\n",
    "    y=X_w2v_pca[:, nth_dims[1]],\n",
    "    nth_dim=nth_dims,\n",
    "    target_names=topics,\n",
    "    s=2,\n",
    "    target_idx_colors=topic_colors,\n",
    "    t='2D projection (random nb components) of the X (Word2vec) matrix using PCA'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nombre de composant principal fitté par le model\n",
    "pca_w2v2 = PCA()\n",
    "pca_w2v2.fit(X_w2v)\n",
    "pca_w2v2.n_components_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut constater que les données la projection des données ne réduit pas la dimension de ces dernier. Celà indique que les données sont bien représenter dans l'espace vectoriel.\n",
    "\n",
    "Cela dit, voyons quel nombre de dimension serait le plus adapter pour grader ```95% d'intertie``` de notre jeu de données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checker combien d'axe factoriel faut-il pour préserver 95% d'inertie de nos jeux de données\n",
    "pca_w2v2_ck = PCA()\n",
    "pca_w2v2_ck.fit(X_w2v)\n",
    "pca_w2v2_ck_cumsum = np.cumsum(pca_w2v2_ck.explained_variance_ratio_)\n",
    "pca_w2v2_ck_d = np.argmax(pca_w2v2_ck_cumsum >= 0.95) + 1\n",
    "pca_w2v2_ck_d # d=130\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manifold learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\rightarrow$ vers une approche t-SNE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous pouvons tracer les embeddings dans un **espace bidimensionnel** qui peut nous montrer comment les mots sont liés.\n",
    "Les mots les plus **similaires** devraient être représentés **en groupes**, tandis que les mots non apparentés apparaîtront à une grande distance. <br><br>\n",
    "\n",
    "Cela nécessite une technique de **réduction de dimension** supplémentaire pour ramener les dimensions à 2 ou 3.\n",
    "La technique de réduction la plus populaire est elle-même une méthode d'embedding: **t-Distributed Stochastic Neighbor Embedding (t-SNE)**.\n",
    "\n",
    "t-SNE est une technique de réduction de la dimensionnalité qui convient parfaitement à la visualisation d'ensembles de données de grande dimension.\n",
    "Il s'agit d'une technique d'apprentissage de type **manifold**, ce qui signifie qu'il tente de faire **correspondre des données de haute dimension à un manifold de plus faible dimension**, créant ainsi un embedding qui tente de maintenir la structure locale des données. Elle est presque exclusivement utilisée pour la visualisation car la sortie est stochastique et elle ne prend pas en charge la transformation de nouvelles données."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE                   # final reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### t-Distributed Sémantic Neighbord Embedding (t-SNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    perplexity=40,\n",
    "    n_components=2,\n",
    "    init='pca',\n",
    "    n_iter=2500,\n",
    "    random_state=123\n",
    ")\n",
    "z = tsne.fit_transform(X_w2v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "nth_dims = (0, 1)\n",
    "points.plot2d(\n",
    "    ax=ax,\n",
    "    x=z[:, nth_dims[0]],\n",
    "    y=z[:, nth_dims[1]],\n",
    "    nth_dim=nth_dims,\n",
    "    target_names=topics,\n",
    "    s=2,\n",
    "    target_idx_colors=topic_colors,\n",
    "    t='2D projection (random nb components) of the X (Word2Vec) matrix using t-SNE'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Locally Linear Embedding (LLE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_neighbors = 100  # neighborhood which is used to recover the locally linear structure\n",
    "n_components = 2  # number of coordinates for the manifold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import manifold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lle_params = {\n",
    "    \"n_neighbors\": n_neighbors,\n",
    "    \"n_components\": n_components,\n",
    "    \"eigen_solver\": \"dense\",\n",
    "    \"random_state\": 123,\n",
    "}\n",
    "\n",
    "lle_standard = manifold.LocallyLinearEmbedding(method=\"standard\", **lle_params)\n",
    "X_w2v_standard_unrolled = lle_standard.fit_transform(X_w2v)\n",
    "\n",
    "lle_ltsa = manifold.LocallyLinearEmbedding(method=\"ltsa\", **lle_params)\n",
    "X_w2v_ltsa_unrolled = lle_ltsa.fit_transform(X_w2v)\n",
    "\n",
    "lle_hessian = manifold.LocallyLinearEmbedding(method=\"hessian\", **lle_params)\n",
    "X_w2v_hessian_unrolled = lle_hessian.fit_transform(X_w2v)\n",
    "\n",
    "lle_mod = manifold.LocallyLinearEmbedding(method=\"modified\", **lle_params)\n",
    "X_w2v_mod_unrolled = lle_mod.fit_transform(X_w2v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#lle = LocallyLinearEmbedding(n_components=5, n_neighbors=100, random_state=42)\n",
    "#X_w2v_unrolled = lle.fit_transform(X_w2v)\n",
    "\n",
    "\n",
    "lle_methods = [\n",
    "    (\"Standard locally linear embedding\", X_w2v_standard_unrolled),\n",
    "    (\"Local tangent space alignment\", X_w2v_ltsa_unrolled),\n",
    "    (\"Hessian eigenmap\", X_w2v_hessian_unrolled),\n",
    "    (\"Modified locally linear embedding\", X_w2v_mod_unrolled),\n",
    "]\n",
    "\n",
    "classes = [\n",
    "    'cacm',\n",
    "    'cisi',\n",
    "    'med',\n",
    "    'cran',\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "nth_dims=(0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"Locally Linear Embeddings\", size=16)\n",
    "\n",
    "for ax, method in zip(axs.flat, lle_methods):\n",
    "    name, X_red = method\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=topic_colors,\n",
    "        cmap='Accent',\n",
    "        s=4,\n",
    "        alpha=1\n",
    "    )\n",
    "    #handles, labels = scatter.legend_elements()\n",
    "    #labels = target_names\n",
    "    #ax.legend(handles, labels, loc=\"upper left\", title=\"Topic\")\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(5)-0.4)\n",
    "    cbar.set_ticks(np.arange(4))\n",
    "    cbar.set_ticklabels(classes, size=10)\n",
    "\n",
    "    ax.set_title(name, size=12)\n",
    "save_fig(\"bbc_W2V_LLEs_plot\")\n",
    "plt.show()\n",
    "#ax.set_title('2D projection (random nb components) of the X (Word2Vec) matrix using t-SNE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Isomap Embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "isomap = manifold.Isomap(\n",
    "    n_neighbors=n_neighbors,\n",
    "    n_components=n_components,\n",
    "    p=30)\n",
    "X_w2v_isomap = isomap.fit_transform(X_w2v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    x=X_w2v_isomap[:, 0],\n",
    "    y=X_w2v_isomap[:, 1],\n",
    "    c=topic_colors,\n",
    "    cmap='Accent',\n",
    "    s=3,\n",
    "    alpha=1\n",
    ")\n",
    "#handles, labels = scatter.legend_elements()\n",
    "#labels = target_names\n",
    "#ax.legend(handles, labels, loc=\"upper left\", title=\"Topic\")\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "cbar.set_ticks(np.arange(5))\n",
    "cbar.set_ticklabels(classes, size=10)\n",
    "ax.set_title('2D projection (random nb components) of the X (Word2Vec) matrix using \\n Isomap Embedding \\n', size=16)\n",
    "save_fig(\"bbc_W2V_ISOMAP_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multidimensional scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "md_scaling = manifold.MDS(\n",
    "    n_components=n_components,\n",
    "    max_iter=2500,\n",
    "    n_init=5,\n",
    "    random_state=123,\n",
    "    normalized_stress='auto',\n",
    ")\n",
    "X_w2v_scaling = md_scaling.fit_transform(X_w2v)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    x=X_w2v_scaling[:, 0],\n",
    "    y=X_w2v_scaling[:, 1],\n",
    "    c=topic_colors,\n",
    "    cmap='Accent',\n",
    "    s=3,\n",
    "    alpha=1\n",
    ")\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "cbar.set_ticks(np.arange(5))\n",
    "cbar.set_ticklabels(classes, size=10)\n",
    "ax.set_title('2D projection (random nb components) of the X (Word2Vec) matrix using \\n Multidimensional scaling \\n', size=16)\n",
    "save_fig(\"bbc_W2V_MultiSCALING_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spectral embedding for non-linear dimensionality reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spectral4w2v = manifold.SpectralEmbedding(\n",
    "    n_components=n_components,\n",
    "    n_neighbors=n_neighbors,\n",
    ")\n",
    "X_w2v_spectral = spectral4w2v.fit_transform(X_w2v)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    x=X_w2v_spectral[:, 0],\n",
    "    y=X_w2v_spectral[:, 1],\n",
    "    c=topic_colors,\n",
    "    cmap='Accent',\n",
    "    s=3,\n",
    "    alpha=1\n",
    ")\n",
    "#handles, labels = scatter.legend_elements()\n",
    "#labels = target_names\n",
    "#ax.legend(handles, labels, loc=\"upper left\", title=\"Topic\")\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "cbar.set_ticks(np.arange(5))\n",
    "cbar.set_ticklabels(classes, size=10)\n",
    "ax.set_title('2D projection (random nb components) of the X (Word2Vec) matrix using \\n Spectral Embedding \\n ', size=16)\n",
    "save_fig(\"bbc_W2V_SpectralEMBEDDING_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### T-distributed Stochastic Neighbor Embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_sne4w2v = manifold.TSNE(\n",
    "    n_components=n_components,\n",
    "    perplexity=30,\n",
    "    init=\"random\",\n",
    "    n_iter=2500,\n",
    "    random_state=123,\n",
    ")\n",
    "X_w2v_tsne = t_sne4w2v.fit_transform(X_w2v)\n",
    "\n",
    "t_sne4w2v_pca = manifold.TSNE(\n",
    "    n_components=n_components,\n",
    "    perplexity=30,\n",
    "    init=\"pca\",\n",
    "    n_iter=2500,\n",
    "    random_state=123,\n",
    ")\n",
    "X_w2v_tsne_pca = t_sne4w2v_pca.fit_transform(X_w2v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsne_inits = [\n",
    "    (\"t-sne init random\", X_w2v_tsne),\n",
    "    (\"t-sne init pca\", X_w2v_tsne_pca)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "fig.suptitle(\"2D projection (random nb components) of the X (Word2Vec) matrix using \\n T-NSE \\n\\n\", size=16)\n",
    "\n",
    "for ax, init in zip(axs.flat, tsne_inits):\n",
    "    name, X_red = init\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=topic_colors,\n",
    "        cmap='Accent',\n",
    "        s=3,\n",
    "        alpha=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "    cbar.set_ticks(np.arange(5))\n",
    "    cbar.set_ticklabels(classes, size=8)\n",
    "    ax.set_title(name, size=12)\n",
    "save_fig(f\"{document_name}_W2V_TSNE_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On a une bonne représentation des données dans le sens où l'on peut identifier les groupe ou clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:#3390FF; font-weight: bold;'>GloVe representation of words</span>\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Principal Component Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# choix arbitraire\n",
    "n_components = 2\n",
    "pca = PCA(n_components=n_components)\n",
    "X_glove_pca = pca.fit_transform(X_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    x=X_glove_pca[:, 0],\n",
    "    y=X_glove_pca[:, 1],\n",
    "    c=topic_colors,\n",
    "    cmap='Accent',\n",
    "    s=3,\n",
    "    alpha=1\n",
    ")\n",
    "\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "cbar.set_ticks(np.arange(5))\n",
    "cbar.set_ticklabels(classes, size=10)\n",
    "ax.set_title('2D projection (random nb components)\\n of the X (Glove) matrix using PCA \\n ', size=16)\n",
    "save_fig(f\"{document_name}_GLOVE_PCA_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\rightarrow$ vers une approche T-SNE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_sne4glove = TSNE(\n",
    "    perplexity=40,\n",
    "    n_components=2,\n",
    "    init='pca',\n",
    "    n_iter=2500,\n",
    "    random_state=123\n",
    ")\n",
    "reduced_glove_tsne = t_sne4glove.fit_transform(X_glove)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    x=reduced_glove_tsne[:, 0],\n",
    "    y=reduced_glove_tsne[:, 1],\n",
    "    c=topic_colors,\n",
    "    cmap='Accent',\n",
    "    s=3,\n",
    "    alpha=1\n",
    ")\n",
    "\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "cbar.set_ticks(np.arange(5))\n",
    "cbar.set_ticklabels(classes, size=10)\n",
    "ax.set_title('2D projection (random nb components)\\n of the X (Glove) matrix using t-SNE \\n', size=16)\n",
    "save_fig(f\"{document_name}_GLOVE_TSNE_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span style='color:green; font-weight: bold;'>Preparing Data frame For machine learning</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\rightarrow$ dataframe\n",
    "- Transformons $\\mathbf{X}$ en dataframe où chaque ligne correspond à un document (ID en index) et chaque colonne correspond à un mot du vocabulaire (les mots en colonne)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_words = pd.DataFrame(\n",
    "#    data = X,\n",
    "#    columns = vocab,\n",
    "#    index = df_text.index\n",
    "#)\n",
    "# df_words\n",
    "\n",
    "# X_docs_bow => bow original (sparce) => not pca\n",
    "# X_docs_bow_red_lsa => lsa reducted\n",
    "# X_docs_bow_red_ipca => ipca reducted\n",
    "\n",
    "# X_docs_tfidf => ifidf original (sparce) => not pca\n",
    "# X_docs_tfidf_lsa => lsa reduced\n",
    "# X_docs_tfidf_red_ipca => ipca reduced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_words_bow = pd.DataFrame(\n",
    "    data = X_docs_bow.toarray(),\n",
    "    index = df_classic4.index,\n",
    "    columns = bow_vectorizer.get_feature_names_out()\n",
    ")\n",
    "df_words_bow.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_words_tfidf = pd.DataFrame(\n",
    "    data = X_docs_tfidf.toarray(),\n",
    "    index = df_classic4.index,\n",
    "    columns = tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "df_words_tfidf.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\rightarrow$ dataframe(words-label)\n",
    "\n",
    "- Jointure entre le dataframe obtenu et la colonne [topic].\n",
    "- Faire le même nuage de points, cette fois-ci en coloriant les points par rapport à la thématique (colonne TOPIC)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bow = df_words_bow.merge(\n",
    "    right = df_classic4.label,\n",
    "    left_index = True,\n",
    "    right_index=True\n",
    ")\n",
    "df_bow.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tfidf = df_words_tfidf.merge(\n",
    "    right = df_classic4.label,\n",
    "    left_index = True,\n",
    "    right_index=True\n",
    ")\n",
    "df_tfidf.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quantifying the quality of clustering results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- homogeneity, which quantifies how much clusters contain only members of a single class;\n",
    "\n",
    "- completeness, which quantifies how much members of a given class are assigned to the same clusters;\n",
    "\n",
    "- V-measure, the harmonic mean of completeness and homogeneity;\n",
    "\n",
    "- Rand-Index, which measures how frequently pairs of data points are grouped consistently according to the result of the clustering algorithm and the ground truth class assignment;\n",
    "\n",
    "- Adjusted Rand-Index, a chance-adjusted Rand-Index such that random cluster assignment have an ARI of 0.0 in expectation.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "from time import sleep\n",
    "\n",
    "evaluations = []\n",
    "evaluations_std = []\n",
    "\n",
    "scores = defaultdict(list)\n",
    "\n",
    "labels = topic_colors\n",
    "\n",
    "def evaluate(labels_, X, name=None, metric=None, dset=None, train_times=None):\n",
    "    scores[\"Homogeneity\"].append(metrics.homogeneity_score(labels, labels_))\n",
    "    scores[\"Completeness\"].append(metrics.completeness_score(labels, labels_))\n",
    "    scores[\"V-measure\"].append(metrics.v_measure_score(labels, labels_))\n",
    "    scores[\"Rand index\"].append(\n",
    "        metrics.rand_score(labels, labels_)\n",
    "    )\n",
    "    scores[\"ARI\"].append(\n",
    "        metrics.adjusted_rand_score(labels, labels_)\n",
    "    )\n",
    "    scores[\"MI\"].append(\n",
    "        metrics.mutual_info_score(labels, labels_)\n",
    "    )\n",
    "    scores[\"NMI\"].append(\n",
    "        metrics.normalized_mutual_info_score(labels, labels_)\n",
    "    )\n",
    "    scores[\"Silhouette Coefficient\"].append(\n",
    "        metrics.silhouette_score(X, labels_, sample_size=2000)\n",
    "    )\n",
    "\n",
    "    evaluation = {\n",
    "        \"dset\": dset,\n",
    "        \"estimator\": name,\n",
    "        \"metric\": metric,\n",
    "        \"train_time\": train_times,\n",
    "    }\n",
    "    evaluation_std = {\n",
    "        \"dset\": dset, # origin or reduced\n",
    "        \"estimator\": name,\n",
    "        \"metric\": metric,\n",
    "        \"train_time\": train_times,\n",
    "    }\n",
    "    for score_name, score_values in scores.items():\n",
    "        mean_score, std_score = np.mean(score_values), np.std(score_values)\n",
    "        print(f\"{score_name}: {mean_score:.3f} ± {std_score:.3f}\")\n",
    "        evaluation[score_name] = mean_score\n",
    "        evaluation_std[score_name] = std_score\n",
    "    evaluations.append(evaluation)\n",
    "    evaluations_std.append(evaluation_std)\n",
    "\n",
    "def fit_and_evaluate(km, X, name=None, metric=None, dset=None, n_runs=5):\n",
    "    name = km.__class__.__name__ if name is None else name\n",
    "\n",
    "    train_times = []\n",
    "    for seed in range(n_runs):\n",
    "\n",
    "        km.set_params(random_state=seed)\n",
    "        t0 = time()\n",
    "        km.fit(X)\n",
    "        train_times.append(time() - t0)\n",
    "        scores[\"Homogeneity\"].append(metrics.homogeneity_score(labels, km.labels_))\n",
    "        scores[\"Completeness\"].append(metrics.completeness_score(labels, km.labels_))\n",
    "        scores[\"V-measure\"].append(metrics.v_measure_score(labels, km.labels_))\n",
    "        scores[\"Rand index\"].append(\n",
    "            metrics.rand_score(labels, km.labels_)\n",
    "        )\n",
    "        scores[\"ARI\"].append(\n",
    "            metrics.adjusted_rand_score(labels, km.labels_)\n",
    "        )\n",
    "        scores[\"MI\"].append(\n",
    "            metrics.mutual_info_score(labels, km.labels_)\n",
    "        )\n",
    "        scores[\"NMI\"].append(\n",
    "            metrics.normalized_mutual_info_score(labels, km.labels_)\n",
    "        )\n",
    "        scores[\"Silhouette Coefficient\"].append(\n",
    "            metrics.silhouette_score(X, km.labels_, sample_size=2000)\n",
    "        )\n",
    "    train_times = np.asarray(train_times)\n",
    "    print(f\"clustering done in {train_times.mean():.2f} ± {train_times.std():.2f} s \")\n",
    "\n",
    "    evaluation = {\n",
    "        \"dset\": dset,\n",
    "        \"estimator\": name,\n",
    "        \"metric\": metric,\n",
    "        \"train_time\": train_times.mean(),\n",
    "    }\n",
    "    evaluation_std = {\n",
    "        \"dset\": dset, # origin or reduced\n",
    "        \"estimator\": name,\n",
    "        \"metric\": metric,\n",
    "        \"train_time\": train_times.std(),\n",
    "    }\n",
    "    for score_name, score_values in scores.items():\n",
    "        mean_score, std_score = np.mean(score_values), np.std(score_values)\n",
    "        print(f\"{score_name}: {mean_score:.3f} ± {std_score:.3f}\")\n",
    "        evaluation[score_name] = mean_score\n",
    "        evaluation_std[score_name] = std_score\n",
    "    evaluations.append(evaluation)\n",
    "    evaluations_std.append(evaluation_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span style='color:green; font-weight: bold;'> Approche Tandem : Réduction de la dimension à laquelle est ajoutée ensuite une tâche de clustering </span>\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import umap\n",
    "import hdbscan # > sudo apt-get install python3.10-dev before\n",
    "\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  <span style='color:#F9A861; font-weight: bold;'> DONNEES ORIGINALES </span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_w2v.shape # wo labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "w2v_umap_emb_irnd = umap.UMAP(\n",
    "    metric='cosine',\n",
    "    random_state=123,\n",
    "    init='random'\n",
    ").fit_transform(X_w2v)\n",
    "\n",
    "w2v_umap_emb_ispt = umap.UMAP(\n",
    "    metric='cosine',\n",
    "    random_state=123,\n",
    "    init='spectral'\n",
    ").fit_transform(X_w2v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(w2v_umap_emb_irnd.shape)\n",
    "print(w2v_umap_emb_ispt.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_methods = [\n",
    "    (\"UMAP metric=cosine, init=random\", w2v_umap_emb_irnd),\n",
    "    (\"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "for ax, method in zip(axs.flat, umap_methods):\n",
    "    name, X_red = method\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=topic_colors,\n",
    "        cmap='Accent',\n",
    "        s=0.1,\n",
    "        alpha=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "    cbar.set_ticks(np.arange(5))\n",
    "    cbar.set_ticklabels(classes, size=10)\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"classic4_W2V_UMAP_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### <span style='color:#3390FF; font-weight: bold;'> K-Means </span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km_w2v = cluster.KMeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=1e-04,\n",
    "    init='random',\n",
    "    random_state=123\n",
    ")\n",
    "km_fit_w2v = km_w2v.fit(X_w2v)\n",
    "km_lab_w2v = km_w2v.fit_predict(X_w2v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_methods = [\n",
    "    ('o1', \"UMAP metric=cosine, init=random\", w2v_umap_emb_irnd, topic_colors, km_w2v.cluster_centers_),\n",
    "    ('c1', \"Check Clustering - UMAP metric=cosine, init=random\", w2v_umap_emb_irnd, km_lab_w2v, km_w2v.cluster_centers_),\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors, km_w2v.cluster_centers_),\n",
    "    ('c2', \"Check Clustering UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, km_lab_w2v, km_w2v.cluster_centers_)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "for ax, method in zip(axs.flat, umap_methods):\n",
    "    tag, name, X_red, cmap, centers = method\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=0.1\n",
    "    )\n",
    "\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    if tag not in ['c1', 'c2']:\n",
    "        cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "        cbar.set_ticks(np.arange(5))\n",
    "        cbar.set_ticklabels(classes, size=10)\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(f\"{document_name}_W2V_ORIGNINAL_VS_KMEANS_CULSTERING_UMAP_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$ Model evaluations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fit_and_evaluate(\n",
    "    km_w2v, # model or estimator\n",
    "    X_w2v, # matrix original\n",
    "    name=\"k-means\",\n",
    "    dset=f\"{document_name}-w2v\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {km_w2v.inertia_:.2f}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$ Elbow method to Estimate number of clusters needs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans_per_k =\\\n",
    "    [cluster.KMeans(\n",
    "    n_clusters=k,\n",
    "    init='random',\n",
    "    n_init=10,\n",
    "    tol=1e-04,\n",
    "    max_iter=300,\n",
    "    random_state=0\n",
    "    ).fit(X_w2v)\n",
    "    for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias = [model.inertia_ for model in kmeans_per_k]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(1,11), inertias, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "save_fig(f\"{document_name}_W2V_BEST_NB_CLUST_DISTORTION_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$ Silhouette method to Estimate number of clusters needs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_scores = [metrics.silhouette_score(X_w2v, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(2,11), silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.tight_layout()\n",
    "save_fig(f\"{document_name}_W2V_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "\n",
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "for k in (3, 4, 5, 6):\n",
    "    plt.subplot(2, 2, k - 2)\n",
    "\n",
    "    y_pred = kmeans_per_k[k - 1].labels_\n",
    "    silhouette_coefficients = silhouette_samples(X_w2v, y_pred)\n",
    "\n",
    "    padding = len(X_w2v) // 30\n",
    "    pos = padding\n",
    "    ticks = []\n",
    "    for i in range(k):\n",
    "        coeffs = silhouette_coefficients[y_pred == i]\n",
    "        coeffs.sort()\n",
    "\n",
    "        color = plt.cm.Spectral(i / k)\n",
    "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ticks.append(pos + len(coeffs) // 2)\n",
    "        pos += len(coeffs) + padding\n",
    "\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
    "    if k in (3, 5):\n",
    "        plt.ylabel(\"Cluster\")\n",
    "\n",
    "    if k in (5, 6):\n",
    "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        plt.xlabel(\"Silhouette Coefficient\")\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "\n",
    "    plt.axvline(x=silhouette_scores[k - 2], color=\"red\", linestyle=\"--\")\n",
    "    plt.title(f\"$k={k}$\")\n",
    "\n",
    "save_fig(f\"{document_name}_KMEANS++_silhouette_analysis_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### <span style='color:#3390FF; font-weight: bold;'> K-Means++ </span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmpp_w2v = cluster.KMeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    init='k-means++',\n",
    "    max_iter=300,\n",
    "    tol=1e-04,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "kmpp_lab_w2v = kmpp_w2v.fit_predict(X_w2v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_methods = [\n",
    "    ('o1', \"UMAP metric=cosine, init=random\", w2v_umap_emb_irnd, topic_colors),\n",
    "    ('c1', \"Check K-mean++ Clustering \\n UMAP metric=cosine, init=random\", w2v_umap_emb_irnd, kmpp_lab_w2v),\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "    ('c2', \"Check K-mean++ Clustering \\n UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, kmpp_lab_w2v)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=10)\n",
    "\n",
    "for ax, method in zip(axs.flat, umap_methods):\n",
    "    tag, name, X_red, cmap = method\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=0.1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    if tag not in ['c1', 'c2']:\n",
    "        cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "        cbar.set_ticks(np.arange(5))\n",
    "        cbar.set_ticklabels(classes, size=8)\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(f\"{document_name}_W2V_ORIGINAL_VS_KMEANS++_CLUSTERING_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$ Model evaluations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fit_and_evaluate(\n",
    "    kmpp_w2v, # model\n",
    "    X_w2v, # matrix original\n",
    "    name=\"k-means++\",\n",
    "    metric=None,\n",
    "    dset=f\"{document_name}-w2v\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {kmpp_w2v.inertia_:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeanspp_per_k = \\\n",
    "    [cluster.KMeans(\n",
    "        n_clusters=k,\n",
    "        init='k-means++',\n",
    "        n_init=10,\n",
    "        tol=1e-04,\n",
    "        max_iter=300,\n",
    "        random_state=0\n",
    "    ).fit(X_w2v)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias = [model.inertia_ for model in kmeanspp_per_k]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$ Elbow method to Estimate number of clusters needs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(1,11), inertias, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "save_fig(f\"{document_name}_W2V_KMEANSPP_BEST_NB_CLUST_DISTORTION_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$  silhouette diagram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "for k in (3, 4, 5, 6):\n",
    "    plt.subplot(2, 2, k - 2)\n",
    "\n",
    "    y_pred = kmeans_per_k[k - 1].labels_\n",
    "    silhouette_coefficients = silhouette_samples(X_w2v, y_pred)\n",
    "\n",
    "    padding = len(X_w2v) // 30\n",
    "    pos = padding\n",
    "    ticks = []\n",
    "    for i in range(k):\n",
    "        coeffs = silhouette_coefficients[y_pred == i]\n",
    "        coeffs.sort()\n",
    "\n",
    "        color = plt.cm.Spectral(i / k)\n",
    "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ticks.append(pos + len(coeffs) // 2)\n",
    "        pos += len(coeffs) + padding\n",
    "\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
    "    if k in (3, 5):\n",
    "        plt.ylabel(\"Cluster\")\n",
    "\n",
    "    if k in (5, 6):\n",
    "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        plt.xlabel(\"Silhouette Coefficient\")\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "\n",
    "    plt.axvline(x=silhouette_scores[k - 2], color=\"red\", linestyle=\"--\")\n",
    "    plt.title(f\"$k={k}$\")\n",
    "\n",
    "save_fig(f\"{document_name}_KMEANS++_silhouette_analysis_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, ***k = 5***, looks like the best option here, as all clusters are roughly the same size,\n",
    "and they all cross the dashed line, which represents the mean silhouette score."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$  Clustering evaluation summary¶\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "df = pd.DataFrame(evaluations[::-1]).set_index(\"estimator\")\n",
    "df_std = pd.DataFrame(evaluations_std[::-1]).set_index(\"estimator\")\n",
    "\n",
    "df.drop(\n",
    "    [\"train_time\"],\n",
    "    axis=\"columns\",\n",
    ").plot.barh(ax=ax0, xerr=df_std)\n",
    "ax0.set_xlabel(\"Clustering scores\")\n",
    "ax0.set_ylabel(\"\")\n",
    "\n",
    "df[\"train_time\"].plot.barh(ax=ax1, xerr=df_std[\"train_time\"])\n",
    "ax1.set_xlabel(\"Clustering time (s)\")\n",
    "plt.tight_layout()\n",
    "######"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### <span style='color:#3390FF; font-weight: bold;'> Kmedoids </span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids, CLARA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmd_w2v_cos = KMedoids(\n",
    "    metric=\"cosine\",\n",
    "    n_clusters=5,\n",
    "    random_state=123,\n",
    "    max_iter=300\n",
    ")\n",
    "\n",
    "kmd_w2v_mnt = KMedoids(\n",
    "    metric=\"manhattan\",\n",
    "    n_clusters=5,\n",
    "    random_state=123,\n",
    "    max_iter=300\n",
    ")\n",
    "\n",
    "clr_w2v_cos = CLARA(\n",
    "    metric=\"cosine\",\n",
    "    n_clusters=5,\n",
    "    init=\"heuristic\",\n",
    "    n_sampling=250,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "clr_w2v_mnt = CLARA(\n",
    "    metric=\"manhattan\",\n",
    "    n_clusters=5,\n",
    "    init=\"heuristic\",\n",
    "    n_sampling=250,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "clustering_algorithms_metrics = [\n",
    "    ('kcos', \"K-Medoid metric=cosine \\n UMAP metric=cosine, init=random\", kmd_w2v_cos),\n",
    "    ('kmnt', \"K-Medoid metric=manathan \\n UMAP metric=cosine, init=random\", kmd_w2v_mnt),\n",
    "    ('rcos', \"CLARA metric=cosine \\n UMAP metric=cosine, init=random\", clr_w2v_cos),\n",
    "    ('rmnt', \"CLARA metric=manathan \\nUMAP metric=cosine, init=spectral\", clr_w2v_mnt),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_mth = [\n",
    "    ('o1', \"UMAP metric=cosine\", w2v_umap_emb_irnd, topic_colors),\n",
    "    ('kc', \"KMenoids metric=cosine\", w2v_umap_emb_irnd, kmpp_lab_w2v),\n",
    "    ('km', \"KMenoids metric=manhattan\", w2v_umap_emb_irnd, kmpp_lab_w2v),\n",
    "]\n",
    "\n",
    "umap_mth_spt = [\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, algorithm in zip(axs.flat, clustering_algorithms_metrics):\n",
    "    tag, name, model = algorithm\n",
    "\n",
    "    # on entraine les modèles\n",
    "    model.fit(X_w2v)\n",
    "\n",
    "    # dépendamment de l'implémentation, on peut avoir des attributs labels_ ou non\n",
    "    if hasattr(model, \"labels_\"):\n",
    "        y_pred = model.labels_.astype(int)\n",
    "    else:\n",
    "        y_pred = model.predict(X_w2v)\n",
    "\n",
    "    # select reduction umap method\n",
    "    X_red = w2v_umap_emb_irnd if umap_init == 'random' else w2v_umap_emb_ispt\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=y_pred,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(f\"{document_name}_KMENOID_VS_CLARA_RANDOM_INIT_CLUSTERING_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fit_and_evaluate(\n",
    "    kmd_w2v_cos, # model\n",
    "    X_w2v, # matrix original\n",
    "    name=\"kmenoid-cos\",\n",
    "    metric=\"cosine\",\n",
    "    dset=f\"{document_name}-w2v\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fit_and_evaluate(\n",
    "    kmd_w2v_mnt, # model\n",
    "    X_w2v, # matrix original\n",
    "    name=\"kmenoid-mnt\",\n",
    "    metric=\"manhattan\",\n",
    "    dset=f\"{document_name}-w2v\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {kmd_w2v_cos.inertia_:.2f}')\n",
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {kmd_w2v_mnt.inertia_:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmenoid_cos_per_k = \\\n",
    "    [KMedoids(\n",
    "        metric=\"cosine\",\n",
    "        n_clusters=k,\n",
    "        random_state=123,\n",
    "        max_iter=300\n",
    "    ).fit(X_w2v)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmenoid_mnt_per_k = \\\n",
    "    [KMedoids(\n",
    "        metric=\"manhattan\",\n",
    "        n_clusters=k,\n",
    "        random_state=123,\n",
    "        max_iter=300\n",
    "    ).fit(X_w2v)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias_kmd_cos = [model.inertia_ for model in kmenoid_cos_per_k]\n",
    "inertias_kmd_mnt = [model.inertia_ for model in kmenoid_mnt_per_k]\n",
    "silhouette_scores_cos = [metrics.silhouette_score(X_w2v, model.labels_)\n",
    "                     for model in kmenoid_cos_per_k[1:]]\n",
    "silhouette_scores_mnt = [metrics.silhouette_score(X_w2v, model.labels_)\n",
    "                     for model in kmenoid_mnt_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$ Elbow method to Estimate number of clusters needs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nbcluster_choice_methods = [\n",
    "    (\"Elbow method - cos\", range(1,11), inertias_kmd_cos, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method - cos\", range(2,11), silhouette_scores_cos, \"Number of clusters\", \"Silhouette score\"),\n",
    "    (\"Elbow method - mnt\", range(1,11), inertias_kmd_mnt, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method - mnt \", range(2,11), silhouette_scores_mnt, \"Number of clusters\", \"Silhouette score\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "for ax, nbclust in zip(axs.flat, nbcluster_choice_methods):\n",
    "    name, x, inertias, xlab, ylab = nbclust\n",
    "    plot = ax.plot(x, inertias, marker='o')\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(name, size=12)\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(f\"{document_name}_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### <span style='color:#3390FF; font-weight: bold;'> Sphérical Kmean </span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from coclust.clustering.spherical_kmeans import SphericalKmeans\n",
    "skm = SphericalKmeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    tol=1e-4,\n",
    "    max_iter=300\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.where(~X_w2v.any(axis=1)) #row 2161 is Zero-valued rows, we add a epsilon for this row"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_w2v[2161,:]=X_w2v[2161,:] + 10**-2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "skm.fit(X_w2v)\n",
    "t = time() - t0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skm_labels = skm.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    labels_= skm_labels, # label\n",
    "    X= X_w2v, # matrix original\n",
    "    name=\"skm\",\n",
    "    metric=None,\n",
    "    dset=f\"{document_name}-w2v\",\n",
    "    train_times=t\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "space = [\n",
    "    ('org', \"Origin\", topic_colors),\n",
    "    ('skm', \"skm (color just means cluster discovered)\", skm_labels)\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, sp in zip(axs.flat, space):\n",
    "    tag, name, cmap = sp\n",
    "\n",
    "    # select reduction umap method\n",
    "    X_red = w2v_umap_emb_irnd if umap_init == 'random' else w2v_umap_emb_ispt\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(f\"{document_name}_KMENOID_VS_CLARA_RANDOM_INIT_CLUSTERING_2Dplot\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### <span style='color:#3390FF; font-weight: bold;'> CAH </span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linkage = (\"ward\", \"average\", \"complete\", \"single\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection CAH of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, lk in zip(axs.flat, linkage):\n",
    "\n",
    "    # select reduction umap method for plotting\n",
    "    X_red = w2v_umap_emb_irnd if umap_init == 'random' else w2v_umap_emb_ispt\n",
    "\n",
    "    clustering = AgglomerativeClustering(linkage=lk, n_clusters=5)\n",
    "    clustering.fit(X_w2v)\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=clustering.labels_,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(f'{lk}', size=11)\n",
    "save_fig(f\"{document_name}_CAH_CLUSTERING_VARIOUS_LINKAGE_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cah_ward_per_k = [AgglomerativeClustering(linkage=\"ward\", n_clusters=k).fit(X_w2v) for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_scores_cah_ward = [metrics.silhouette_score(X_w2v, model.labels_) for model in cah_ward_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "plot = ax.plot(range(2,11), silhouette_scores_cah_ward, marker='o')\n",
    "ax.set_xlabel(\"Number of clusters\")\n",
    "ax.set_ylabel(\"Silhouette score\")\n",
    "ax.set_title(\"Silhouette method - ward\", size=12)\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(f\"{document_name}_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cah_ward_per_linkage_k5 = [AgglomerativeClustering(linkage=lk, n_clusters=5).fit(X_w2v) for lk in linkage]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "cah_single = AgglomerativeClustering(linkage=\"single\", n_clusters=5).fit(X_w2v)\n",
    "t = time() - t0\n",
    "evaluate(labels_= cah_single.labels_, X= X_w2v, name=\"cah-single\", metric=None, dset=f\"{document_name}-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"average\", n_clusters=5).fit(X_w2v)\n",
    "t = time() - t0\n",
    "evaluate(labels_= cah_single.labels_, X= X_w2v, name=\"cah-average\", metric=None, dset=f\"{document_name}-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of Labels produced by the average cah is 1: impossible to evaluate it with evaluate function ( problem in computing silhouette score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"complete\", n_clusters=5).fit(X_w2v)\n",
    "t = time() - t0\n",
    "evaluate(labels_= cah_single.labels_, X= X_w2v, name=\"cah-complete\", metric=None, dset=f\"{document_name}-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"ward\", n_clusters=5).fit(X_w2v)\n",
    "t = time() - t0\n",
    "evaluate(labels_= cah_single.labels_, X= X_w2v, name=\"cah-ward\", metric=None, dset=f\"{document_name}-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of Labels produced by the ward cah is 1: impossible to evaluate it with evaluate function ( problem in computing silhouette score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(20, 10), sharey=True)\n",
    "\n",
    "df_clust_ori = pd.DataFrame(evaluations[::-1]).set_index(\"estimator\")\n",
    "df_clust_ori_std = pd.DataFrame(evaluations_std[::-1]).set_index(\"estimator\")\n",
    "\n",
    "df_clust_ori.drop(\n",
    "    [\"train_time\", \"dset\", \"metric\"], # we don't need plotting those (non--numeric)\n",
    "    axis=\"columns\",\n",
    ").plot.barh(ax=ax0, xerr=df_clust_ori_std)\n",
    "ax0.set_xlabel(\"Clustering scores\")\n",
    "ax0.set_ylabel(\"\")\n",
    "\n",
    "df_clust_ori[\"train_time\"].plot.barh(ax=ax1, xerr=df_clust_ori_std[\"train_time\"])\n",
    "ax1.set_xlabel(\"Clustering time (s)\")\n",
    "plt.tight_layout()\n",
    "######"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summary dataframe of clustering on original data\n",
    "df_clust_ori.head(n=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clust_ori.to_latex(\n",
    "    index=[\"estimator\"],\n",
    "    columns=[\"ARI\", \"PMI\", \"NMI\", \"Silhouette Coefficient\"],\n",
    "    formatters={\"name\": str.upper},\n",
    "    float_format=\"{:.2f}\".format,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:#F9A861; font-weight: bold;'> DONNEES REDUITES </span>\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMAGES_PATH = Path.cwd().parent.parent / \"images\" / \"unsupervised_learning\" / f\"{document_name}-red\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "from time import sleep\n",
    "\n",
    "evaluations_red = []\n",
    "evaluations_red_std = []\n",
    "\n",
    "scores_red = defaultdict(list)\n",
    "\n",
    "labels = topic_colors\n",
    "\n",
    "def evaluate_red(labels_, X, name=None, metric=None, dset=None, train_times=None):\n",
    "    scores_red[\"Homogeneity\"].append(metrics.homogeneity_score(labels, labels_))\n",
    "    scores_red[\"Completeness\"].append(metrics.completeness_score(labels, labels_))\n",
    "    scores_red[\"V-measure\"].append(metrics.v_measure_score(labels, labels_))\n",
    "    scores_red[\"Rand index\"].append(\n",
    "        metrics.rand_score(labels, labels_)\n",
    "    )\n",
    "    scores_red[\"ARI\"].append(\n",
    "        metrics.adjusted_rand_score(labels, labels_)\n",
    "    )\n",
    "    scores_red[\"MI\"].append(\n",
    "        metrics.mutual_info_score(labels, labels_)\n",
    "    )\n",
    "    scores_red[\"NMI\"].append(\n",
    "        metrics.normalized_mutual_info_score(labels, labels_)\n",
    "    )\n",
    "    scores_red[\"Silhouette Coefficient\"].append(\n",
    "        metrics.silhouette_score(X, labels_, sample_size=2000)\n",
    "    )\n",
    "\n",
    "    evaluation_red = {\n",
    "        \"dset\": dset,\n",
    "        \"estimator\": name,\n",
    "        \"metric\": metric,\n",
    "        \"train_time\": train_times,\n",
    "    }\n",
    "    evaluation_red_std = {\n",
    "        \"dset\": dset, # origin or reduced\n",
    "        \"estimator\": name,\n",
    "        \"metric\": metric,\n",
    "        \"train_time\": train_times,\n",
    "    }\n",
    "    for score_name, score_values in scores_red.items():\n",
    "        mean_score, std_score = np.mean(score_values), np.std(score_values)\n",
    "        print(f\"{score_name}: {mean_score:.3f} ± {std_score:.3f}\")\n",
    "        evaluation_red[score_name] = mean_score\n",
    "        evaluation_red_std[score_name] = std_score\n",
    "    evaluations_red.append(evaluation_red)\n",
    "    evaluations_red_std.append(evaluation_red_std)\n",
    "\n",
    "def fit_and_evaluate_red(km, X, name=None, metric=None, dset=None, n_runs=5):\n",
    "    name = km.__class__.__name__ if name is None else name\n",
    "\n",
    "    train_times = []\n",
    "    for seed in range(n_runs):\n",
    "\n",
    "        km.set_params(random_state=seed)\n",
    "        t0 = time()\n",
    "        km.fit(X)\n",
    "        train_times.append(time() - t0)\n",
    "        scores_red[\"Homogeneity\"].append(metrics.homogeneity_score(labels, km.labels_))\n",
    "        scores_red[\"Completeness\"].append(metrics.completeness_score(labels, km.labels_))\n",
    "        scores_red[\"V-measure\"].append(metrics.v_measure_score(labels, km.labels_))\n",
    "        scores_red[\"Rand index\"].append(\n",
    "            metrics.rand_score(labels, km.labels_)\n",
    "        )\n",
    "        scores_red[\"ARI\"].append(\n",
    "            metrics.adjusted_rand_score(labels, km.labels_)\n",
    "        )\n",
    "        scores_red[\"MI\"].append(\n",
    "            metrics.mutual_info_score(labels, km.labels_)\n",
    "        )\n",
    "        scores_red[\"NMI\"].append(\n",
    "            metrics.normalized_mutual_info_score(labels, km.labels_)\n",
    "        )\n",
    "        scores_red[\"Silhouette Coefficient\"].append(\n",
    "            metrics.silhouette_score(X, km.labels_, sample_size=2000)\n",
    "        )\n",
    "    train_times = np.asarray(train_times)\n",
    "    print(f\"clustering done in {train_times.mean():.2f} ± {train_times.std():.2f} s \")\n",
    "\n",
    "    evaluation_red = {\n",
    "        \"dset\": dset,\n",
    "        \"estimator\": name,\n",
    "        \"metric\": metric,\n",
    "        \"train_time\": train_times.mean(),\n",
    "    }\n",
    "    evaluation_red_std = {\n",
    "        \"dset\": dset, # origin or reduced\n",
    "        \"estimator\": name,\n",
    "        \"metric\": metric,\n",
    "        \"train_time\": train_times.std(),\n",
    "    }\n",
    "    for score_name, score_values in scores_red.items():\n",
    "        mean_score, std_score = np.mean(score_values), np.std(score_values)\n",
    "        print(f\"{score_name}: {mean_score:.3f} ± {std_score:.3f}\")\n",
    "        evaluation_red[score_name] = mean_score\n",
    "        evaluation_red_std[score_name] = std_score\n",
    "    evaluations_red.append(evaluation_red)\n",
    "    evaluations_red_std.append(evaluation_red_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### >> <span style='color:#3390FF; font-weight: bold;'> UMAP</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Kmeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km_w2v_red = cluster.KMeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=1e-04,\n",
    "    init='random',\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "km_w2v_red_rnd_fit = km_w2v_red.fit(w2v_umap_emb_irnd)\n",
    "km_w2v_red_spt_fit = km_w2v_red.fit(w2v_umap_emb_ispt)\n",
    "\n",
    "km_lab_w2v_umap_emb_irnd = km_w2v_red.fit_predict(w2v_umap_emb_irnd)\n",
    "km_lab_w2v_umap_emb_spt = km_w2v_red.fit_predict(w2v_umap_emb_ispt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_methods = [\n",
    "    ('o1', \"UMAP metric=cosine, init=random\", w2v_umap_emb_irnd, topic_colors),\n",
    "    ('c1', \"Check Clustering - UMAP metric=cosine, init=random\", w2v_umap_emb_irnd, km_lab_w2v_umap_emb_irnd),\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "    ('c2', \"Check Clustering UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, km_lab_w2v_umap_emb_spt)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "for ax, method in zip(axs.flat, umap_methods):\n",
    "    tag, name, X_red, cmap = method\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=0.1\n",
    "    )\n",
    "\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    if tag not in ['c1', 'c2']:\n",
    "        cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "        cbar.set_ticks(np.arange(len(classes)))\n",
    "        cbar.set_ticklabels(classes, size=10)\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"classic4_W2V_ORIGNINAL_VS_KMEANS_CULSTERING_UMAP_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random reducted\n",
    "fit_and_evaluate_red(\n",
    "    km_w2v_red, # model or estimator\n",
    "    w2v_umap_emb_irnd, # matrix original\n",
    "    name=\"k-means _ rnd\",\n",
    "    dset=\"classic4-w2v-rnd-red\"\n",
    ")\n",
    "print(\"========\")\n",
    "# spectral reduced\n",
    "fit_and_evaluate_red(\n",
    "    km_w2v_red,  # model or estimator\n",
    "    w2v_umap_emb_ispt,  # matrix original\n",
    "    name=\"k-means _ spt\",\n",
    "    dset=\"classic4-w2v-spt-red\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {km_w2v_red_rnd_fit.inertia_:.2f}')\n",
    "print(f'Distortion: {km_w2v_red_spt_fit.inertia_:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$  Elbow method to Estimate number of clusters needs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans_rnd_per_k = \\\n",
    "    [cluster.KMeans(\n",
    "        n_clusters=k,\n",
    "        init='random',\n",
    "        n_init=10,\n",
    "        tol=1e-04,\n",
    "        max_iter=300,\n",
    "        random_state=0\n",
    "    ).fit(w2v_umap_emb_irnd)\n",
    "     for k in range(1, 11)]\n",
    "\n",
    "kmeans_spt_per_k = \\\n",
    "    [cluster.KMeans(\n",
    "        n_clusters=k,\n",
    "        init='random',\n",
    "        n_init=10,\n",
    "        tol=1e-04,\n",
    "        max_iter=300,\n",
    "        random_state=0\n",
    "    ).fit(w2v_umap_emb_ispt)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias_rnd = [model.inertia_ for model in kmeans_rnd_per_k]\n",
    "inertias_spt = [model.inertia_ for model in kmeans_spt_per_k]\n",
    "silhouette_scores_rnd = [metrics.silhouette_score(w2v_umap_emb_irnd, model.labels_)\n",
    "                         for model in kmeans_rnd_per_k[1:]]\n",
    "silhouette_scores_spt = [metrics.silhouette_score(w2v_umap_emb_ispt, model.labels_)\n",
    "                         for model in kmeans_spt_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nbcluster_choice_methods = [\n",
    "    (\"Elbow method - rnd\", range(1,11), inertias_rnd, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method -spt\", range(2,11), silhouette_scores_rnd, \"Number of clusters\", \"Silhouette score\"),\n",
    "    (\"Elbow method - rnd\", range(1,11), inertias_spt, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method -spt \", range(2,11), silhouette_scores_spt, \"Number of clusters\", \"Silhouette score\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "for ax, nbclust in zip(axs.flat, nbcluster_choice_methods):\n",
    "    name, x, inertias, xlab, ylab = nbclust\n",
    "    plot = ax.plot(x, inertias, marker='o')\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(name, size=12)\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"bbc_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Kmeans++"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmpp_w2v_red = cluster.KMeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=1e-04,\n",
    "    init='k-means++',\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "kmpp_w2v_red_rnd_fit = kmpp_w2v_red.fit(w2v_umap_emb_irnd)\n",
    "kmpp_w2v_red_spt_fit = kmpp_w2v_red.fit(w2v_umap_emb_ispt)\n",
    "\n",
    "kmpp_lab_w2v_umap_emb_irnd = kmpp_w2v_red.fit_predict(w2v_umap_emb_irnd)\n",
    "kmpp_lab_w2v_umap_emb_spt = kmpp_w2v_red.fit_predict(w2v_umap_emb_ispt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_methods = [\n",
    "    ('o1', \"UMAP metric=cosine, init=random\", w2v_umap_emb_irnd, topic_colors),\n",
    "    ('c1', \"Check Clustering - UMAP metric=cosine, init=random\", w2v_umap_emb_irnd, kmpp_lab_w2v_umap_emb_irnd),\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "    ('c2', \"Check Clustering UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, kmpp_lab_w2v_umap_emb_spt)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "for ax, method in zip(axs.flat, umap_methods):\n",
    "    tag, name, X_red, cmap = method\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=0.1\n",
    "    )\n",
    "\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    if tag not in ['c1', 'c2']:\n",
    "        cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "        cbar.set_ticks(np.arange(len(classes)))\n",
    "        cbar.set_ticklabels(classes, size=10)\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"classic4_W2V_ORIGNINAL_VS_KMEANS_CULSTERING_UMAP_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random reducted\n",
    "fit_and_evaluate_red(\n",
    "    kmpp_w2v_red, # model or estimator\n",
    "    w2v_umap_emb_irnd, # matrix original\n",
    "    name=\"k-means++ - rnd\",\n",
    "    dset=\"classic4-w2v-rnd-red\"\n",
    ")\n",
    "print(\"========\")\n",
    "# spectral reduced\n",
    "fit_and_evaluate_red(\n",
    "    kmpp_w2v_red,  # model or estimator\n",
    "    w2v_umap_emb_ispt,  # matrix original\n",
    "    name=\"k-means++ - spt\",\n",
    "    dset=\"classic4-w2v-spt-red\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {km_w2v_red_rnd_fit.inertia_:.2f}')\n",
    "print(f'Distortion: {km_w2v_red_spt_fit.inertia_:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$  Elbow method to Estimate number of clusters needs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeanspp_rnd_per_k = \\\n",
    "    [cluster.KMeans(\n",
    "        n_clusters=k,\n",
    "        init='k-means++',\n",
    "        n_init=10,\n",
    "        tol=1e-04,\n",
    "        max_iter=300,\n",
    "        random_state=0\n",
    "    ).fit(w2v_umap_emb_irnd)\n",
    "     for k in range(1, 11)]\n",
    "\n",
    "kmeanspp_spt_per_k = \\\n",
    "    [cluster.KMeans(\n",
    "        n_clusters=k,\n",
    "        init='k-means++',\n",
    "        n_init=10,\n",
    "        tol=1e-04,\n",
    "        max_iter=300,\n",
    "        random_state=0\n",
    "    ).fit(w2v_umap_emb_ispt)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias_rnd = [model.inertia_ for model in kmeanspp_rnd_per_k]\n",
    "inertias_spt = [model.inertia_ for model in kmeanspp_spt_per_k]\n",
    "silhouette_scores_rnd = [metrics.silhouette_score(w2v_umap_emb_irnd, model.labels_)\n",
    "                         for model in kmeanspp_rnd_per_k[1:]]\n",
    "silhouette_scores_spt = [metrics.silhouette_score(w2v_umap_emb_ispt, model.labels_)\n",
    "                         for model in kmeanspp_spt_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nbcluster_choice_methods = [\n",
    "    (\"Elbow method - rnd\", range(1,11), inertias_rnd, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method -spt\", range(2,11), silhouette_scores_rnd, \"Number of clusters\", \"Silhouette score\"),\n",
    "    (\"Elbow method - rnd\", range(1,11), inertias_spt, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method -spt \", range(2,11), silhouette_scores_spt, \"Number of clusters\", \"Silhouette score\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "for ax, nbclust in zip(axs.flat, nbcluster_choice_methods):\n",
    "    name, x, inertias, xlab, ylab = nbclust\n",
    "    plot = ax.plot(x, inertias, marker='o')\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(name, size=12)\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"classic4_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Kmedoids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmd_w2v_red_cos = KMedoids(\n",
    "    metric=\"cosine\",\n",
    "    n_clusters=5,\n",
    "    random_state=123,\n",
    "    max_iter=300\n",
    ")\n",
    "\n",
    "kmd_w2v_red_mnt = KMedoids(\n",
    "    metric=\"manhattan\",\n",
    "    n_clusters=5,\n",
    "    random_state=123,\n",
    "    max_iter=300\n",
    ")\n",
    "\n",
    "clr_w2v_red_cos = CLARA(\n",
    "    metric=\"cosine\",\n",
    "    n_clusters=5,\n",
    "    init=\"heuristic\",\n",
    "    n_sampling=250,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "clr_w2v_red_mnt = CLARA(\n",
    "    metric=\"manhattan\",\n",
    "    n_clusters=5,\n",
    "    init=\"heuristic\",\n",
    "    n_sampling=250,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "clustering_algorithms_metrics = [\n",
    "    ('kcos', \"K-Medoid metric=cosine \\n UMAP metric=cosine, init=random\", kmd_w2v_red_cos),\n",
    "    ('kmnt', \"K-Medoid metric=manathan \\n UMAP metric=cosine, init=random\", kmd_w2v_red_mnt),\n",
    "    ('rcos', \"CLARA metric=cosine \\n UMAP metric=cosine, init=random\", clr_w2v_red_cos),\n",
    "    ('rmnt', \"CLARA metric=manathan \\nUMAP metric=cosine, init=spectral\", clr_w2v_red_mnt),\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_mth = [\n",
    "    ('o1', \"UMAP metric=cosine\", w2v_umap_emb_irnd, topic_colors),\n",
    "    ('kc', \"KMenoids metric=cosine\", w2v_umap_emb_irnd, kmpp_lab_w2v),\n",
    "    ('km', \"KMenoids metric=manhattan\", w2v_umap_emb_irnd, kmpp_lab_w2v),\n",
    "]\n",
    "\n",
    "umap_mth_spt = [\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "    ('o2', \"UMAP metric=cosine, init=spectral\", w2v_umap_emb_ispt, topic_colors),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, algorithm in zip(axs.flat, clustering_algorithms_metrics):\n",
    "    tag, name, model = algorithm\n",
    "\n",
    "    # on entraine les modèles\n",
    "    model.fit(X_w2v)\n",
    "\n",
    "    # dépendamment de l'implémentation, on peut avoir des attributs labels_ ou non\n",
    "    if hasattr(model, \"labels_\"):\n",
    "        y_pred = model.labels_.astype(int)\n",
    "    else:\n",
    "        y_pred = model.predict(w2v_umap_emb_irnd)\n",
    "\n",
    "    # select reduction umap method for plotting\n",
    "    X_red = w2v_umap_emb_irnd if umap_init == 'random' else w2v_umap_emb_ispt\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=y_pred,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"classic4_KMENOID_VS_CLARA_RANDOM_INIT_CLUSTERING_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fit_and_evaluate_red(\n",
    "    kmd_w2v_red_cos, # model\n",
    "    w2v_umap_emb_irnd, # matrix original\n",
    "    name=\"kmenoid-cos\",\n",
    "    metric=\"cosine\",\n",
    "    dset=\"classic4-w2v-rnd-red\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fit_and_evaluate_red(\n",
    "    kmd_w2v_red_mnt, # model\n",
    "    w2v_umap_emb_irnd, # matrix original\n",
    "    name=\"kmenoid-mnt\",\n",
    "    metric=\"manhattan\",\n",
    "    dset=\"classic4-w2v-rnd-red\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {kmd_w2v_red_cos.inertia_:.2f}')\n",
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {kmd_w2v_red_mnt.inertia_:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmd_rnd_red_cos_per_k = \\\n",
    "    [KMedoids(\n",
    "        metric=\"cosine\",\n",
    "        n_clusters=k,\n",
    "        random_state=123,\n",
    "        max_iter=300\n",
    "    ).fit(w2v_umap_emb_irnd)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmd_rnd_red_mnt_per_k = \\\n",
    "    [KMedoids(\n",
    "        metric=\"manhattan\",\n",
    "        n_clusters=k,\n",
    "        random_state=123,\n",
    "        max_iter=300\n",
    "    ).fit(w2v_umap_emb_irnd)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias_kmd_cos = [model.inertia_ for model in kmd_rnd_red_cos_per_k]\n",
    "inertias_kmd_mnt = [model.inertia_ for model in kmd_rnd_red_mnt_per_k]\n",
    "silhouette_scores_cos = [metrics.silhouette_score(w2v_umap_emb_irnd, model.labels_)\n",
    "                         for model in kmenoid_cos_per_k[1:]]\n",
    "silhouette_scores_mnt = [metrics.silhouette_score(w2v_umap_emb_irnd, model.labels_)\n",
    "                         for model in kmenoid_mnt_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$ Elbow method to Estimate number of clusters needs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nbcluster_choice_methods = [\n",
    "    (\"Elbow method - cos\", range(1,11), inertias_kmd_cos, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method - cos\", range(2,11), silhouette_scores_cos, \"Number of clusters\", \"Silhouette score\"),\n",
    "    (\"Elbow method - mnt\", range(1,11), inertias_kmd_mnt, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method - mnt \", range(2,11), silhouette_scores_mnt, \"Number of clusters\", \"Silhouette score\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "for ax, nbclust in zip(axs.flat, nbcluster_choice_methods):\n",
    "    name, x, inertias, xlab, ylab = nbclust\n",
    "    plot = ax.plot(x, inertias, marker='o')\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(name, size=12)\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"bbc_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Sphérical Kmean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skm = SphericalKmeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    tol=1e-4,\n",
    "    max_iter=300\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "skm.fit(w2v_umap_emb_irnd)\n",
    "t = time() - t0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skm_labels = skm.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_red(\n",
    "    labels_= skm_labels, # label\n",
    "    X= w2v_umap_emb_irnd, # matrix original\n",
    "    name=\"skm _ rnd\",\n",
    "    metric=None,\n",
    "    dset=\"bbc-rnd-red-w2v\",\n",
    "    train_times=t\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "space = [\n",
    "    ('org', \"Origin\", topic_colors),\n",
    "    ('skm', \"skm (color just means cluster discovered)\", skm_labels)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, sp in zip(axs.flat, space):\n",
    "    tag, name, cmap = sp\n",
    "\n",
    "    # select reduction umap method\n",
    "    X_red = w2v_umap_emb_irnd if umap_init == 'random' else w2v_umap_emb_ispt\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"bbc_KMENOID_VS_CLARA_RANDOM_INIT_CLUSTERING_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  CAH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection CAH of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, lk in zip(axs.flat, linkage):\n",
    "\n",
    "    # select reduction umap method for plotting\n",
    "    X_red = w2v_umap_emb_irnd if umap_init == 'random' else w2v_umap_emb_ispt\n",
    "\n",
    "    clustering = AgglomerativeClustering(linkage=lk, n_clusters=5)\n",
    "    clustering.fit(w2v_umap_emb_irnd)\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=clustering.labels_,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(f'{lk}', size=11)\n",
    "save_fig(\"bbc_CAH_CLUSTERING_VARIOUS_LINKAGE_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cah_ward_per_k = [AgglomerativeClustering(linkage=\"ward\", n_clusters=k).fit(w2v_umap_emb_irnd) for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_scores_cah_ward = [metrics.silhouette_score(w2v_umap_emb_irnd, model.labels_) for model in cah_ward_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "plot = ax.plot(range(2,11), silhouette_scores_cah_ward, marker='o')\n",
    "ax.set_xlabel(\"Number of clusters\")\n",
    "ax.set_ylabel(\"Silhouette score\")\n",
    "ax.set_title(\"Silhouette method - ward\", size=12)\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"classic4_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cah_ward_per_linkage_k5 = [AgglomerativeClustering(linkage=lk, n_clusters=5).fit(w2v_umap_emb_irnd) for lk in linkage]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "cah_single = AgglomerativeClustering(linkage=\"single\", n_clusters=5).fit(w2v_umap_emb_irnd)\n",
    "t = time() - t0\n",
    "evaluate_red(labels_= cah_single.labels_, X= w2v_umap_emb_irnd, name=\"cah-single\", metric=None, dset=\"bbc-rnd-red-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"average\", n_clusters=5).fit(w2v_umap_emb_irnd)\n",
    "t = time() - t0\n",
    "evaluate_red(labels_= cah_single.labels_, X= w2v_umap_emb_irnd, name=\"cah-average\", metric=None, dset=\"bbc-rnd-red-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"complete\", n_clusters=5).fit(w2v_umap_emb_irnd)\n",
    "t = time() - t0\n",
    "evaluate_red(labels_= cah_single.labels_, X= w2v_umap_emb_irnd, name=\"cah-complete\", metric=None, dset=\"classic4-rnd-red-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"ward\", n_clusters=5).fit(w2v_umap_emb_irnd)\n",
    "t = time() - t0\n",
    "evaluate_red(labels_= cah_single.labels_, X= w2v_umap_emb_irnd, name=\"cah-ward\", metric=None, dset=\"classic4-rnd-red-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(20, 10), sharey=True)\n",
    "\n",
    "df = pd.DataFrame(evaluations_red[::-1]).set_index(\"estimator\")\n",
    "df_std = pd.DataFrame(evaluations_red_std[::-1]).set_index(\"estimator\")\n",
    "\n",
    "df.drop(\n",
    "    [\"train_time\", \"dset\", \"metric\"], # we don't need plotting those (non--numeric)\n",
    "    axis=\"columns\",\n",
    ").plot.barh(ax=ax0, xerr=df_std)\n",
    "ax0.set_xlabel(\"Clustering scores\")\n",
    "ax0.set_ylabel(\"\")\n",
    "\n",
    "df[\"train_time\"].plot.barh(ax=ax1, xerr=df_std[\"train_time\"])\n",
    "ax1.set_xlabel(\"Clustering time (s)\")\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### >> <span style='color:#3390FF; font-weight: bold;'> PCA </span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# réinitialisation\n",
    "evaluations_red = []\n",
    "evaluations_red_std = []\n",
    "scores_red = defaultdict(list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMAGES_PATH = Path.cwd().parent.parent / \"images\" / \"unsupervised_learning\" / \"bbc-red-pca\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Kmeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km_w2v_pca_red = cluster.KMeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=1e-04,\n",
    "    init='random',\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "km_w2v_pca_red_fit = km_w2v_pca_red.fit(X_w2v_pca)\n",
    "km_lab_w2v_pca_red = km_w2v_red.fit_predict(X_w2v_pca)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_methods = [\n",
    "    ('o1', \"PCA metric=cosine, init=random\", X_w2v_pca, topic_colors),\n",
    "    ('c1', \"Check Clustering - PCA, init=random\", X_w2v_pca, km_lab_w2v_pca_red)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n\", size=12)\n",
    "\n",
    "for ax, method in zip(axs.flat, pca_methods):\n",
    "    tag, name, X_red, cmap = method\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=0.1\n",
    "    )\n",
    "\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    if tag not in ['c1', 'c2']:\n",
    "        cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "        cbar.set_ticks(np.arange(5))\n",
    "        cbar.set_ticklabels(classes, size=10)\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"bbc_W2V_ORIGNINAL_VS_KMEANS_CULSTERING_PCA_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random reducted\n",
    "fit_and_evaluate_red(\n",
    "    km_w2v_pca_red, # model or estimator\n",
    "    X_w2v_pca, # matrix original\n",
    "    name=\"k-means _ pca\",\n",
    "    dset=\"bbc-w2v-pca-red\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Distortion: {km_w2v_pca_red_fit.inertia_:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans_pca_per_k = \\\n",
    "    [cluster.KMeans(\n",
    "        n_clusters=k,\n",
    "        init='random',\n",
    "        n_init=10,\n",
    "        tol=1e-04,\n",
    "        max_iter=300,\n",
    "        random_state=0\n",
    "    ).fit(X_w2v_pca)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias_pca = [model.inertia_ for model in kmeans_pca_per_k]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_scores_pca = [metrics.silhouette_score(X_w2v_pca, model.labels_)\n",
    "                         for model in kmeans_pca_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nbcluster_choice_methods = [\n",
    "    (\"Elbow method - pca\", range(1,11), inertias_pca, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method - pca\", range(2,11), silhouette_scores_pca, \"Number of clusters\", \"Silhouette score\"),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 6))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "for ax, nbclust in zip(axs.flat, nbcluster_choice_methods):\n",
    "    name, x, inertias, xlab, ylab = nbclust\n",
    "    plot = ax.plot(x, inertias, marker='o')\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(name, size=12)\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"bbc_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Kmeans ++"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmpp_w2v_pca_red = cluster.KMeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=1e-04,\n",
    "    init='k-means++',\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "kmpp_w2v_pca_red_fit = kmpp_w2v_red.fit(X_w2v_pca)\n",
    "kmpp_lab_w2v_pca_red = kmpp_w2v_red.fit_predict(X_w2v_pca)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_methods = [\n",
    "    ('o1', \"PCA, init=random\", X_w2v_pca, topic_colors),\n",
    "    ('c1', \"Check Clustering - PCA, init=random\", X_w2v_pca, kmpp_lab_w2v_pca_red),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 6))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n PCA Embedding \\n\", size=12)\n",
    "\n",
    "for ax, method in zip(axs.flat, umap_methods):\n",
    "    tag, name, X_red, cmap = method\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=0.1\n",
    "    )\n",
    "\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    if tag not in ['c1', 'c2']:\n",
    "        cbar = fig.colorbar(scatter, ax=ax, boundaries=np.arange(6)-0.4)\n",
    "        cbar.set_ticks(np.arange(5))\n",
    "        cbar.set_ticklabels(classes, size=10)\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"bbc_W2V_ORIGNINAL_VS_KMEANS_CULSTERING_PCA_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fit_and_evaluate_red(\n",
    "    kmpp_w2v_pca_red, # model or estimator\n",
    "    X_w2v_pca, # matrix original\n",
    "    name=\"k-means++ - pca\",\n",
    "    dset=\"bbc-w2v-pca-red\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {km_w2v_pca_red_fit.inertia_:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeanspp_pca_per_k = \\\n",
    "    [cluster.KMeans(\n",
    "        n_clusters=k,\n",
    "        init='k-means++',\n",
    "        n_init=10,\n",
    "        tol=1e-04,\n",
    "        max_iter=300,\n",
    "        random_state=0\n",
    "    ).fit(X_w2v_pca)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias_pca = [model.inertia_ for model in kmeanspp_pca_per_k]\n",
    "silhouette_scores_pca = [metrics.silhouette_score(X_w2v_pca, model.labels_) for model in kmeanspp_pca_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nbcluster_choice_methods = [\n",
    "    (\"Elbow method - rnd\", range(1,11), inertias_pca, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method -spt\", range(2,11), silhouette_scores_pca, \"Number of clusters\", \"Silhouette score\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(11, 6))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "for ax, nbclust in zip(axs.flat, nbcluster_choice_methods):\n",
    "    name, x, inertias, xlab, ylab = nbclust\n",
    "    plot = ax.plot(x, inertias, marker='o')\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(name, size=12)\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"bbc_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Kmedoids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmd_w2v_red_cos = KMedoids(\n",
    "    metric=\"cosine\",\n",
    "    n_clusters=5,\n",
    "    random_state=123,\n",
    "    max_iter=300\n",
    ")\n",
    "\n",
    "kmd_w2v_red_mnt = KMedoids(\n",
    "    metric=\"manhattan\",\n",
    "    n_clusters=5,\n",
    "    random_state=123,\n",
    "    max_iter=300\n",
    ")\n",
    "\n",
    "clr_w2v_red_cos = CLARA(\n",
    "    metric=\"cosine\",\n",
    "    n_clusters=5,\n",
    "    init=\"heuristic\",\n",
    "    n_sampling=250,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "clr_w2v_red_mnt = CLARA(\n",
    "    metric=\"manhattan\",\n",
    "    n_clusters=5,\n",
    "    init=\"heuristic\",\n",
    "    n_sampling=250,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "clustering_algorithms_metrics = [\n",
    "    ('kcos', \"K-Medoid metric=cosine \\n PCA, init=random\", kmd_w2v_red_cos),\n",
    "    ('kmnt', \"K-Medoid metric=manathan \\n PCA, init=random\", kmd_w2v_red_mnt),\n",
    "    ('rcos', \"CLARA metric=cosine \\n PCA, init=random\", clr_w2v_red_cos),\n",
    "    ('rmnt', \"CLARA metric=manathan \\nPCA, init=spectral\", clr_w2v_red_mnt),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using\\n PCA\\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, algorithm in zip(axs.flat, clustering_algorithms_metrics):\n",
    "    tag, name, model = algorithm\n",
    "\n",
    "    # on entraine les modèles\n",
    "    model.fit(X_w2v_pca)\n",
    "\n",
    "    # dépendamment de l'implémentation, on peut avoir des attributs labels_ ou non\n",
    "    if hasattr(model, \"labels_\"):\n",
    "        y_pred = model.labels_.astype(int)\n",
    "    else:\n",
    "        y_pred = model.predict(X_w2v_pca)\n",
    "\n",
    "    # select reduction umap method for plotting\n",
    "    X_red = X_w2v_pca\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=y_pred,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"bbc_KMENOID_VS_CLARA_RANDOM_INIT_CLUSTERING_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fit_and_evaluate_red(\n",
    "    kmd_w2v_red_cos, # model\n",
    "    X_w2v_pca, # matrix original\n",
    "    name=\"kmenoid-cos\",\n",
    "    metric=\"cosine\",\n",
    "    dset=\"bbc-w2v-pca-red\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pourcentage of variance or distortion\n",
    "print(f'Distortion: {kmd_w2v_red_cos.inertia_:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmd_pca_red_cos_per_k = \\\n",
    "    [KMedoids(\n",
    "        metric=\"cosine\",\n",
    "        n_clusters=k,\n",
    "        random_state=123,\n",
    "        max_iter=300\n",
    "    ).fit(X_w2v_pca)\n",
    "     for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias_kmd_cos = [model.inertia_ for model in kmd_pca_red_cos_per_k]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_scores_cos = [metrics.silhouette_score(X_w2v_pca, model.labels_)\n",
    "                         for model in kmd_pca_red_cos_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### $\\rightarrow$ Silhouette method to Estimate number of clusters needs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nbcluster_choice_methods = [\n",
    "    (\"Elbow method - cos\", range(1,11), inertias_kmd_cos, \"Number of clusters\", \"Distortion\"),\n",
    "    (\"Silhouette method - cos\", range(2,11), silhouette_scores_cos, \"Number of clusters\", \"Silhouette score\"),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(11, 6))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "for ax, nbclust in zip(axs.flat, nbcluster_choice_methods):\n",
    "    name, x, inertias, xlab, ylab = nbclust\n",
    "    plot = ax.plot(x, inertias, marker='o')\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(name, size=12)\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"bbc_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Sphérical Kmean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skm = SphericalKmeans(\n",
    "    n_clusters=5,\n",
    "    n_init=10,\n",
    "    tol=1e-4,\n",
    "    max_iter=300\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "skm.fit(X_w2v_pca)\n",
    "t = time() - t0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skm_labels = skm.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_red(\n",
    "    labels_= skm_labels, # label\n",
    "    X= X_w2v_pca, # matrix original\n",
    "    name=\"skm _ rnd\",\n",
    "    metric=None,\n",
    "    dset=\"bbc-pca-red-w2v\",\n",
    "    train_times=t\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "space = [\n",
    "    ('org', \"Origin\", topic_colors),\n",
    "    ('skm', \"skm (color just means cluster discovered)\", skm_labels)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(11, 6))\n",
    "fig.suptitle(\"2D projection of the X (W2V) matrix using \\n UMAP Embedding \\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, sp in zip(axs.flat, space):\n",
    "    tag, name, cmap = sp\n",
    "\n",
    "    # select reduction umap method\n",
    "    X_red = X_w2v_pca\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=cmap,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(name, size=11)\n",
    "save_fig(\"bbc_KMENOID_VS_CLARA_RANDOM_INIT_CLUSTERING_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  CAH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle(\"2D projection CAH of the X (W2V) matrix using \\n PCA Embedding \\n\", size=12)\n",
    "\n",
    "umap_init = 'random' #  ou 'spectral'\n",
    "for ax, lk in zip(axs.flat, linkage):\n",
    "\n",
    "    # select reduction umap method for plotting\n",
    "    X_red = X_w2v_pca\n",
    "\n",
    "    clustering = AgglomerativeClustering(linkage=lk, n_clusters=5)\n",
    "    clustering.fit(X_w2v_pca)\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x=X_red[:, 0],\n",
    "        y=X_red[:, 1],\n",
    "        c=clustering.labels_,\n",
    "        cmap='Accent',\n",
    "        s=1\n",
    "    )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    # no need color bar caused we performed unsupervised clustering\n",
    "    # Let's kmeans discover cluster. So no need color bar when view clusters\n",
    "    ax.set_title(f'{lk}', size=11)\n",
    "save_fig(\"bbc_CAH_CLUSTERING_VARIOUS_LINKAGE_2Dplot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cah_ward_per_k = [AgglomerativeClustering(linkage=\"ward\", n_clusters=k).fit(X_w2v_pca) for k in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_scores_cah_ward = [metrics.silhouette_score(X_w2v_pca, model.labels_) for model in cah_ward_per_k[1:]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "fig.suptitle(\"nb clust checking checkout\", size=16)\n",
    "\n",
    "plot = ax.plot(range(2,11), silhouette_scores_cah_ward, marker='o')\n",
    "ax.set_xlabel(\"Number of clusters\")\n",
    "ax.set_ylabel(\"Silhouette score\")\n",
    "ax.set_title(\"Silhouette method - ward\", size=12)\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"bbc_W2V_KMENOID_BEST_NB_CLUST_SILHOUETTE_SCORE_Line_plot\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cah_ward_per_linkage_k5 = [AgglomerativeClustering(linkage=lk, n_clusters=5).fit(X_w2v_pca) for lk in linkage]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "cah_single = AgglomerativeClustering(linkage=\"single\", n_clusters=5).fit(X_w2v_pca)\n",
    "t = time() - t0\n",
    "evaluate_red(labels_= cah_single.labels_, X= X_w2v_pca, name=\"cah-single\", metric=None, dset=\"bbc-pca-red-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"average\", n_clusters=5).fit(X_w2v_pca)\n",
    "t = time() - t0\n",
    "evaluate_red(labels_= cah_single.labels_, X= X_w2v_pca, name=\"cah-average\", metric=None, dset=\"bbc-pca-red-w2v\", train_times=t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"complete\", n_clusters=5).fit(X_w2v_pca)\n",
    "t = time() - t0\n",
    "evaluate_red(labels_= cah_single.labels_, X= X_w2v_pca, name=\"cah-complete\", metric=None, dset=\"bbc-pca-red-w2v\", train_times=t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "AgglomerativeClustering(linkage=\"ward\", n_clusters=5).fit(X_w2v_pca)\n",
    "t = time() - t0\n",
    "evaluate_red(labels_= cah_single.labels_, X= X_w2v_pca, name=\"cah-ward\", metric=None, dset=\"bbc-pca-red-w2v\", train_times=t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(20, 10), sharey=True)\n",
    "\n",
    "df = pd.DataFrame(evaluations_red[::-1]).set_index(\"estimator\")\n",
    "df_std = pd.DataFrame(evaluations_red_std[::-1]).set_index(\"estimator\")\n",
    "\n",
    "df.drop(\n",
    "    [\"train_time\", \"dset\", \"metric\"], # we don't need plotting those (non--numeric)\n",
    "    axis=\"columns\",\n",
    ").plot.barh(ax=ax0, xerr=df_std)\n",
    "ax0.set_xlabel(\"Clustering scores\")\n",
    "ax0.set_ylabel(\"\")\n",
    "\n",
    "df[\"train_time\"].plot.barh(ax=ax1, xerr=df_std[\"train_time\"])\n",
    "ax1.set_xlabel(\"Clustering time (s)\")\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### >> <span style='color:#3390FF; font-weight: bold;'> t-SNE</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reinitialise\n",
    "evaluations_red_std = []\n",
    "scores_red = defaultdict(list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMAGES_PATH = Path.cwd().parent.parent / \"images\" / \"unsupervised_learning\" / \"bbc-red-tse\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### >> >> >>  Kmeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
